{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Red Panda \u00b6 Redpanda is a new storage engine, optimized for streaming data, using a thread-per-core architecture focused on delivering stable tail-latencies Value Propositions \u00b6 Kafka compatible cluster. C++ engine. Single binary to deploy. No more zookeeper. It uses the Raft consensus algorithm internally. Up to 10x lower tail latencies and 6x faster Kafka transactions on fewer resources. Zero data loss by default, highly available and predictable performance at scale Limitless processing of both real-time and historical data through a single API. Redpanda Keeper (RPK) automatically tunes your kernel to yield the optimal settings for your hardware Transform data with our WebAssembly-based engine. With cloud offering Automated backups to S3/GCS EDA positioning \u00b6 Many of the benefits of an event-processing system can be found in a simple pub/sub process or database that collects events from application components and makes them available to other components. Data as a product: you transform your event stream from individual actions into a warehouse of information about everything that happens in your application Kafka counters \u00b6 Kafka\u2019s default configuration may acknowledge writes before fsync. This might allow Kafka to lose messages when nodes fail. Performance \u00b6 uses DMA (Direct Memory Access) for all its disk IO place the data directory (/var/lib/redpanda/data) on an XFS partition in a local NVMe SSD automatically chooses the best setting to drive high throughput traffic to the machine. everage cgroups to isolate the Redpanda processes leverage systemd slices, to strongly prefer evicting other processes before evicting RedPanda process\u2019 memory and to reserve IO quotas and CPU time CPU is configured for predictable latency at all times Tiered Storage \u00b6 Tiered Storage allows you to save storage costs by offloading log segments to cloud storage. You can specify the amount of local storage that you want to provision and configure Tiered Storage to move the rest to Amazon S3 or Google Cloud Storage. Redpanda Tiered Storage works behind the scenes to index where data is offloaded so that it can retrieve the data when you need it. You can enable Tiered Storage for a cluster or for a topic. Remote write is the process that constantly uploads log segments to cloud storage. The process is created for each partition and runs on the leader node of the partition. Architecture \u00b6 Getting started \u00b6 See Platform to get the product , or docker docker run -d --pull = always --name = redpanda-1 --rm \\ -p 8081 :8081 \\ -p 8082 :8082 \\ -p 9092 :9092 \\ -p 9644 :9644 \\ docker.redpanda.com/vectorized/redpanda:latest redpanda start --overprovisioned \\ --smp 1 --memory 1G --reserve-memory 0M --node-id 0 --check = false # Start a shell docker exec -ti redpanda-1 bash # use rpk commands See also the docker compose under studies/redpanda folder. rpk common commands \u00b6 # on macos directly rpk container start # cluster rpk cluster info --brokers .... # Topic rpk topic create twitch_chat --brokers = localhost:9092 # produce text message like kafka-console-producer rpk topic produce twitch_chat --brokers = localhost:9092 # Consume rpk topic consume twitch_chat --brokers = localhost:9092 # Edit cluster config rpk cluster config edit Data transformation with WebAssembly \u00b6 Scenario \u00b6 Inject flights data to RedPanda then to Pinot . [flights-schema.json] to define the flights table in Pinot Create topic in redpanda: docker exec -ti redpanda-1 bash rpk topic create flights Create table in Pino docker exec -ti pinot-controller bash ./bin/pinot-admin.sh AddTable -schemaFile /tmp/panda_airlines/flights-schema.json -tableConfigFile /tmp/panda_airlines/flights-table-realtime.json -exec Produce message to the flights topic rpk topic produce flights < /tmp/panda_airlines/flights-data.json Connect to the pinot web console chrome localhost:9001 Execute the following query in the Query Console to verify the connection to Kafka has worked and the table in Pinot is loaded with records from flights topic: select * from flights limit 10 Then execute the following SQL to address the analyst's request: Find the number of flights that occurred in January 2014 that have air time of more than 300 minutes and that are from any airport in the state of California to JFK airport. select count ( * ) from flights where Dest = 'JFK' and AirTime > 300 and OriginStateName = 'California' and Month = 1 and Year = 2014 Read more Raft consensus algorithm","title":"Home"},{"location":"#red-panda","text":"Redpanda is a new storage engine, optimized for streaming data, using a thread-per-core architecture focused on delivering stable tail-latencies","title":"Red Panda"},{"location":"#value-propositions","text":"Kafka compatible cluster. C++ engine. Single binary to deploy. No more zookeeper. It uses the Raft consensus algorithm internally. Up to 10x lower tail latencies and 6x faster Kafka transactions on fewer resources. Zero data loss by default, highly available and predictable performance at scale Limitless processing of both real-time and historical data through a single API. Redpanda Keeper (RPK) automatically tunes your kernel to yield the optimal settings for your hardware Transform data with our WebAssembly-based engine. With cloud offering Automated backups to S3/GCS","title":"Value Propositions"},{"location":"#eda-positioning","text":"Many of the benefits of an event-processing system can be found in a simple pub/sub process or database that collects events from application components and makes them available to other components. Data as a product: you transform your event stream from individual actions into a warehouse of information about everything that happens in your application","title":"EDA positioning"},{"location":"#kafka-counters","text":"Kafka\u2019s default configuration may acknowledge writes before fsync. This might allow Kafka to lose messages when nodes fail.","title":"Kafka counters"},{"location":"#performance","text":"uses DMA (Direct Memory Access) for all its disk IO place the data directory (/var/lib/redpanda/data) on an XFS partition in a local NVMe SSD automatically chooses the best setting to drive high throughput traffic to the machine. everage cgroups to isolate the Redpanda processes leverage systemd slices, to strongly prefer evicting other processes before evicting RedPanda process\u2019 memory and to reserve IO quotas and CPU time CPU is configured for predictable latency at all times","title":"Performance"},{"location":"#tiered-storage","text":"Tiered Storage allows you to save storage costs by offloading log segments to cloud storage. You can specify the amount of local storage that you want to provision and configure Tiered Storage to move the rest to Amazon S3 or Google Cloud Storage. Redpanda Tiered Storage works behind the scenes to index where data is offloaded so that it can retrieve the data when you need it. You can enable Tiered Storage for a cluster or for a topic. Remote write is the process that constantly uploads log segments to cloud storage. The process is created for each partition and runs on the leader node of the partition.","title":"Tiered Storage"},{"location":"#architecture","text":"","title":"Architecture"},{"location":"#getting-started","text":"See Platform to get the product , or docker docker run -d --pull = always --name = redpanda-1 --rm \\ -p 8081 :8081 \\ -p 8082 :8082 \\ -p 9092 :9092 \\ -p 9644 :9644 \\ docker.redpanda.com/vectorized/redpanda:latest redpanda start --overprovisioned \\ --smp 1 --memory 1G --reserve-memory 0M --node-id 0 --check = false # Start a shell docker exec -ti redpanda-1 bash # use rpk commands See also the docker compose under studies/redpanda folder.","title":"Getting started"},{"location":"#rpk-common-commands","text":"# on macos directly rpk container start # cluster rpk cluster info --brokers .... # Topic rpk topic create twitch_chat --brokers = localhost:9092 # produce text message like kafka-console-producer rpk topic produce twitch_chat --brokers = localhost:9092 # Consume rpk topic consume twitch_chat --brokers = localhost:9092 # Edit cluster config rpk cluster config edit","title":"rpk common commands"},{"location":"#data-transformation-with-webassembly","text":"","title":"Data transformation with WebAssembly"},{"location":"#scenario","text":"Inject flights data to RedPanda then to Pinot . [flights-schema.json] to define the flights table in Pinot Create topic in redpanda: docker exec -ti redpanda-1 bash rpk topic create flights Create table in Pino docker exec -ti pinot-controller bash ./bin/pinot-admin.sh AddTable -schemaFile /tmp/panda_airlines/flights-schema.json -tableConfigFile /tmp/panda_airlines/flights-table-realtime.json -exec Produce message to the flights topic rpk topic produce flights < /tmp/panda_airlines/flights-data.json Connect to the pinot web console chrome localhost:9001 Execute the following query in the Query Console to verify the connection to Kafka has worked and the table in Pinot is loaded with records from flights topic: select * from flights limit 10 Then execute the following SQL to address the analyst's request: Find the number of flights that occurred in January 2014 that have air time of more than 300 minutes and that are from any airport in the state of California to JFK airport. select count ( * ) from flights where Dest = 'JFK' and AirTime > 300 and OriginStateName = 'California' and Month = 1 and Year = 2014 Read more Raft consensus algorithm","title":"Scenario"}]}